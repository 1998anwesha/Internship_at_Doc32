{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References-https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/ , https://github.com/lincolnhard/head-pose-estimation/blob/master/video_test_shape.py , https://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/\n",
    "\n",
    "The dlib package can work upto python 3.6, not later versions so I needed to create a virtualenv of python 3.6 and then install dlib. \"shape_predictor_68_face_landmarks.py\" file needs to be downloaded and kept in the same directory as that of the virtualenv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import matplotlib as plt\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-time face landmarks detection using webcam to detect the required coordinates on a detected face. Our pre-trained model directory, \"shape_predictor_68_face_landmarks.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"shape_predictor_68_face_landmarks.py\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D coordinates of a few points : In the case of a face, the corners of the eyes, the tip of the nose, corners of the mouth\n",
    "etc are chosen. Dlibâ€™s facial landmark detector provides us with many points to choose from. \n",
    "\n",
    "3D locations of the same points : the 3D location of the 2D feature points are needed. \n",
    "The 3D locations of a few points in some arbitrary reference frame are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using Videocapture to get live feed from webcam and we get into the loop only if the webcam is working.\n",
    "The detected face is grayscaled and landmarks are found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Defining a function to  calculate the angle by which the face is tilted from the correct posture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(p1, p2):\n",
    "    #print(p1[1], p2[1], p1[0], p2[0])\n",
    "    if (p1[0] - p2[0])!=0:\n",
    "        m1 = (p2[1] - p1[1])/(p1[0] - p2[0])\n",
    "    else:\n",
    "        m1=0\n",
    "        \n",
    "    if m1!=0:\n",
    "        angle = int(math.atan(1/m1)*180/math.pi)   \n",
    "        \n",
    "    else:\n",
    "        angle=90\n",
    "        \n",
    "    \n",
    "    if(p2[0] > p1[0] and p2[1] < p1[1]):\n",
    "        angle = -1 * (180 - angle)\n",
    "    elif(p2[0] < p1[0] and p2[1] < p1[1]):\n",
    "        angle = (180 + angle)\n",
    "    #print(angle)\n",
    "    return angle   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/Jun/2020 13:44:46] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\app.py\", line 2464, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\app.py\", line 2450, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\app.py\", line 1867, in handle_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\envs\\dlib_env\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-7-647dcee32119>\", line 15, in hello\n",
      "    \n",
      "cv2.error: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, image = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detection of faces into webcam's image\n",
    "    rects = detector(gray)\n",
    "    \n",
    "    \n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # Make the prediction and transfom it to numpy array\n",
    "        shape = predictor(gray, rect)\n",
    "        #print(shape)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "               \n",
    "    \n",
    "    #print(shape)\n",
    "    #2D image points, here only the six required coordinates are taken\n",
    "    image_points = np.array([\n",
    "\n",
    "                                shape[30],     # Nose tip\n",
    "\n",
    "                                shape[8],     # Chin\n",
    "\n",
    "                                shape[36],     # Left eye left corner\n",
    "\n",
    "                                shape[45],     # Right eye right corne\n",
    "\n",
    "                                shape[48],     # Left Mouth corner\n",
    "\n",
    "                                shape[54]      # Right mouth corner\n",
    "\n",
    "                            ], dtype=\"double\")\n",
    "\n",
    "\n",
    "    # 3D model points --> universal for all images--World Coordinates \n",
    "\n",
    "    model_points = np.array([\n",
    "                                (0.0, 0.0, 0.0),             # Nose tip\n",
    "\n",
    "                                (0.0, -330.0, -65.0),        # Chin\n",
    "\n",
    "                                (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "\n",
    "                                (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "\n",
    "                                (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "\n",
    "                                (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "\n",
    "\n",
    "                         \n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    " \n",
    "    #We can approximate the optical center by the center of the image, approximate the focal length by the width of the image\n",
    "    #in pixels and assume that radial distortion does not exist.\n",
    "    size = image.shape\n",
    "    \n",
    "    focal_length = size[1]\n",
    "\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "\n",
    "    camera_matrix = np.array(\n",
    "\n",
    "                             [[focal_length, 0, center[0]],\n",
    "\n",
    "                             [0, focal_length, center[1]],\n",
    "\n",
    "                             [0, 0, 1]], dtype = \"double\"\n",
    "\n",
    "                             )\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "    \n",
    "    #SOLVEPNP_ITERATIVE Iterative method is based on Levenberg-Marquardt optimization. In this case, the\n",
    "    #function finds such a pose that minimizes reprojection error, that is the sum of squared distances\n",
    "    #between the observed projections imagePoints and the projected (using projectPoints() ) objectPoints .\n",
    "\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, \n",
    "                                                              flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    # Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "\n",
    "    # We use this to draw a line sticking out of the nose\n",
    "\n",
    " \n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, \n",
    "                                                 translation_vector, camera_matrix, dist_coeffs)\n",
    "\n",
    "    #Draw on our image, all the required six cordinate points (x,y)\n",
    "    for p in image_points:\n",
    "\n",
    "        cv2.circle(image, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "    p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
    "\n",
    "    p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "\n",
    " \n",
    "    cv2.line(image, p1, p2, (255,0,0), 2)#for drawing the 3d line from the nose tip\n",
    "    \n",
    "    #Specifying the parameters required in the function putText which is used to write text on images\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX  \n",
    "    org = (10, 20) \n",
    "    fontScale = 0.5\n",
    "    color = (0, 255, 0) \n",
    "    thickness = 1 \n",
    "    \n",
    "    \n",
    "    angle=func(p1,p2)\n",
    "    \n",
    "    #From the angle obtained we get to know the direction in which one must rotate one's head\n",
    "    if(angle < -20 and angle > -160):\n",
    "        image = cv2.putText(image, \"Tilt head towards left\", org, font, fontScale, color, thickness, cv2.LINE_AA) \n",
    "    elif(angle > 20 and angle < 160):\n",
    "        image = cv2.putText(image, \"Tilt head towards right\", org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    else:\n",
    "        image = cv2.putText(image, \"Perfect! Open your mouth\", org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    # Show the image\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    \n",
    "    #press q for exiting and turning off the webcam\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from matplotlib import pyplot as plt\n",
    "#plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlib_env",
   "language": "python",
   "name": "dlib_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
